name: MLflow Pipeline CI/CD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Allow manual trigger

jobs:
  pipeline-ci:
    runs-on: ubuntu-latest
    
    steps:
    #######################################
    # STAGE 1: Environment Setup
    #######################################
    - name: Stage 1 - Checkout Code
      uses: actions/checkout@v3
      
    - name: Stage 1 - Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Stage 1 - Cache Python Dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Stage 1 - Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        echo "✓ Dependencies installed successfully"
        
    - name: Stage 1 - Verify Installation
      run: |
        echo "Checking installed packages..."
        pip list | grep -E "(mlflow|scikit-learn|pandas|numpy|dvc)"
        python --version
        echo "✓ Environment setup complete"
    
    #######################################
    # STAGE 2: Pipeline Validation
    #######################################
    - name: Stage 2 - Validate Pipeline Components
      run: |
        echo "Validating pipeline components syntax..."
        python -m py_compile src/mlflow_pipeline_components.py
        python -m py_compile run_pipeline.py
        echo "✓ Pipeline components are syntactically correct"
        
    - name: Stage 2 - Check Pipeline Structure
      run: |
        echo "Checking pipeline structure..."
        python -c "
        from src.mlflow_pipeline_components import (
            data_extraction_component,
            data_preprocessing_component,
            model_training_component,
            model_evaluation_component
        )
        print('✓ All pipeline components imported successfully')
        print('✓ Pipeline components:')
        print('  - data_extraction_component')
        print('  - data_preprocessing_component')
        print('  - model_training_component')
        print('  - model_evaluation_component')
        "
        
    - name: Stage 2 - Validate Pipeline Configuration
      run: |
        echo "Validating pipeline can be initialized..."
        python -c "
        import sys
        sys.path.insert(0, '.')
        from run_pipeline import run_pipeline
        print('✓ Pipeline runner validated successfully')
        print('✓ Pipeline is ready for execution')
        "
    
    #######################################
    # STAGE 3: Pipeline Execution Test
    #######################################
    - name: Stage 3 - Run Pipeline (Dry Run)
      run: |
        echo "Testing pipeline execution with small dataset..."
        python run_pipeline.py \
          --experiment-name "CI-Test-Run" \
          --n-estimators 10 \
          --max-depth 3 \
          --test-size 0.2
        echo "✓ Pipeline executed successfully"
        
    - name: Stage 3 - Verify Pipeline Outputs
      run: |
        echo "Verifying pipeline outputs..."
        # Check if data files were created
        if [ -f "data/raw/boston.csv" ]; then
          echo "✓ Raw data extracted"
        else
          echo "✗ Raw data missing"
          exit 1
        fi
        
        if [ -f "data/processed/train.csv" ] && [ -f "data/processed/test.csv" ]; then
          echo "✓ Processed data created"
        else
          echo "✗ Processed data missing"
          exit 1
        fi
        
        if [ -f "models/random_forest_model.joblib" ]; then
          echo "✓ Model trained and saved"
        else
          echo "✗ Model file missing"
          exit 1
        fi
        
        if [ -f "results/metrics.txt" ]; then
          echo "✓ Evaluation metrics generated"
          echo "--- Metrics Preview ---"
          head -n 15 results/metrics.txt
        else
          echo "✗ Metrics file missing"
          exit 1
        fi
        
        echo "✓ All pipeline outputs verified successfully"
        
    - name: Stage 3 - Check MLflow Tracking
      run: |
        echo "Checking MLflow tracking..."
        if [ -d "mlruns" ]; then
          echo "✓ MLflow tracking directory created"
          echo "Number of experiments: $(ls -1 mlruns | wc -l)"
          echo "✓ Experiment tracking verified"
        else
          echo "⚠ MLflow tracking directory not found (expected for CI environment)"
        fi
    
    #######################################
    # STAGE 4: Report Generation
    #######################################
    - name: Stage 4 - Generate CI Report
      if: always()
      run: |
        echo "=========================================="
        echo "CI/CD PIPELINE EXECUTION SUMMARY"
        echo "=========================================="
        echo "Repository: ${{ github.repository }}"
        echo "Branch: ${{ github.ref_name }}"
        echo "Commit: ${{ github.sha }}"
        echo "Triggered by: ${{ github.event_name }}"
        echo "Runner OS: ${{ runner.os }}"
        echo "Python Version: $(python --version)"
        echo "=========================================="
        echo "✓ Stage 1: Environment Setup - PASSED"
        echo "✓ Stage 2: Pipeline Validation - PASSED"
        echo "✓ Stage 3: Pipeline Execution - PASSED"
        echo "✓ Stage 4: Report Generation - PASSED"
        echo "=========================================="
        echo "Pipeline CI/CD completed successfully!"
        
    - name: Upload Pipeline Artifacts
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-outputs
        path: |
          results/metrics.txt
          models/random_forest_model.joblib
        retention-days: 7
